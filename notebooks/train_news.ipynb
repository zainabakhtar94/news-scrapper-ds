{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/08 17:13:41 WARN Utils: Your hostname, zainab-ThinkPad-T560 resolves to a loopback address: 127.0.1.1; using 192.168.178.29 instead (on interface wlp4s0)\n",
      "22/11/08 17:13:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/zainab/miniconda3/envs/sparknlp/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/zainab/miniconda3/envs/sparknlp/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/zainab/.ivy2/cache\n",
      "The jars for the packages stored in: /home/zainab/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-cd08efa3-9240-401c-9f0e-3700a0b69f95;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.1.0 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in local-m2-cache\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in local-m2-cache\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      ":: resolution report :: resolve 1289ms :: artifacts dl 61ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.1.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from local-m2-cache in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   0   |   0   |   0   ||   17  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-cd08efa3-9240-401c-9f0e-3700a0b69f95\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 17 already retrieved (0kB/36ms)\n",
      "22/11/08 17:13:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/11/08 17:13:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "# spark = sparknlp.start()\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"6G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.1.0\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|               title|subject|\n",
      "+--------------------+-------+\n",
      "|Delay in registra...|  crime|\n",
      "|IHCRA fixes Rs1, ...| health|\n",
      "|Pakistan reopens ...|  other|\n",
      "|NA body anxious o...|  other|\n",
      "|Timely, generous ...|  other|\n",
      "|Inspiring STEM Ca...|  other|\n",
      "|Putin says pipeli...|  other|\n",
      "|All six babies bo...|  scary|\n",
      "|Hadiqa Kiani to r...|  other|\n",
      "|Pak squad leaves ...|  other|\n",
      "|Terrorism is terr...|  crime|\n",
      "|Will you be able ...|  other|\n",
      "|Will you be able ...|  other|\n",
      "|Bye-polls on 12 s...|  other|\n",
      "|No electricity bi...|  other|\n",
      "|LHC issues notice...|  other|\n",
      "|Govt ‘using relig...|  other|\n",
      "|Alvi stresses ‘gi...|  other|\n",
      "|US ignores Indian...|  other|\n",
      "|Taliban deny Jais...|  scary|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('./tmp/news.parquet')\n",
    "# df = spark.read.csv(\"oldnews.csv\",header=True,inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|               title|subject|\n",
      "+--------------------+-------+\n",
      "|Delay in registra...|  crime|\n",
      "|IHCRA fixes Rs1, ...| health|\n",
      "|Pakistan reopens ...|  other|\n",
      "|NA body anxious o...|  other|\n",
      "|Timely, generous ...|  other|\n",
      "|Inspiring STEM Ca...|  other|\n",
      "|Putin says pipeli...|  other|\n",
      "|All six babies bo...|  scary|\n",
      "|Hadiqa Kiani to r...|  other|\n",
      "|Pak squad leaves ...|  other|\n",
      "|Terrorism is terr...|  crime|\n",
      "|Will you be able ...|  other|\n",
      "|Will you be able ...|  other|\n",
      "|Bye-polls on 12 s...|  other|\n",
      "|No electricity bi...|  other|\n",
      "|LHC issues notice...|  other|\n",
      "|Govt ‘using relig...|  other|\n",
      "|Alvi stresses ‘gi...|  other|\n",
      "|US ignores Indian...|  other|\n",
      "|Taliban deny Jais...|  scary|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-------+\n",
      "|               title|subject|\n",
      "+--------------------+-------+\n",
      "|Delay in registra...|  crime|\n",
      "|IHCRA fixes Rs1, ...| health|\n",
      "|Pakistan reopens ...|  other|\n",
      "|NA body anxious o...|  other|\n",
      "|Timely, generous ...|  other|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('title','subject').show()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|subject|count|\n",
      "+-------+-----+\n",
      "|  scary|    3|\n",
      "|  crime|  248|\n",
      "|   null| 4175|\n",
      "|  other|  931|\n",
      "| health|   23|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Value Counts\n",
    "df.groupBy('subject').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other     931\n",
       "crime     248\n",
       "health     23\n",
       "scary       3\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Counts via pandas\n",
    "df.toPandas()['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4175"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check For Missing Values\n",
    "df.toPandas()['subject'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Missing Values\n",
    "df = df.dropna(subset=('subject'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature\n",
    "# Load Our Transformer & Extractor Pkgs\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages For the Pipeline\n",
    "tokenizer = Tokenizer(inputCol='title',outputCol='mytokens')\n",
    "stopwords_remover = StopWordsRemover(inputCol='mytokens',outputCol='filtered_tokens')\n",
    "vectorizer = CountVectorizer(inputCol='filtered_tokens',outputCol='rawFeatures')\n",
    "idf = IDF(inputCol='rawFeatures',outputCol='vectorizedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding/LabelIndexing\n",
    "labelEncoder = StringIndexer(inputCol='subject',outputCol='label').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+\n",
      "|               title|subject|label|\n",
      "+--------------------+-------+-----+\n",
      "|Delay in registra...|  crime|  1.0|\n",
      "|IHCRA fixes Rs1, ...| health|  2.0|\n",
      "|Pakistan reopens ...|  other|  0.0|\n",
      "|NA body anxious o...|  other|  0.0|\n",
      "|Timely, generous ...|  other|  0.0|\n",
      "+--------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelEncoder.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict of Labels\n",
    "label_dict = {'other':0.0,\n",
    " 'crime':1.0,\n",
    " 'health':2.0,\n",
    " 'scary':3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = labelEncoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+\n",
      "|               title|subject|label|\n",
      "+--------------------+-------+-----+\n",
      "|Delay in registra...|  crime|  1.0|\n",
      "|IHCRA fixes Rs1, ...| health|  2.0|\n",
      "|Pakistan reopens ...|  other|  0.0|\n",
      "|NA body anxious o...|  other|  0.0|\n",
      "|Timely, generous ...|  other|  0.0|\n",
      "+--------------------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split Dataset\n",
    "(trainDF,testDF) = df.randomSplit((0.7,0.3),seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Estimator\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='vectorizedFeatures',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,stopwords_remover,vectorizer,idf,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building MOdel\n",
    "lr_model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_model.save(\"./trained_pipelines/classifier_pipeline\")\n",
    "# loadedPipeline = PipelineModel.load(\"./sentimentdl_pipeline\")\n",
    "# loadedPipeline.transform(YOUR_DATAFRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on our Test Dataset\n",
    "predictions = lr_model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               title|subject|label|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|$3 billion on the...|  other|  0.0|[$3, billion, on,...|  [$3, billion, way]|(2853,[348,2335],...|(2853,[348,2335],...|[13.7350531307451...|[0.99999995935182...|       0.0|\n",
      "|10 killed, two in...|  crime|  1.0|[10, killed,, two...|[10, killed,, two...|(2853,[11,34,69,2...|(2853,[11,34,69,2...|[-13.196458622153...|[3.95848358977358...|       1.0|\n",
      "|13 people die in ...|  crime|  1.0|[13, people, die,...|[13, people, die,...|(2853,[13,14,16,7...|(2853,[13,14,16,7...|[12.0155517729986...|[0.99999951612974...|       0.0|\n",
      "|148 students to l...|  other|  0.0|[148, students, t...|[148, students, l...|(2853,[202,2283],...|(2853,[202,2283],...|[14.0373767044725...|[0.99999996875660...|       0.0|\n",
      "|19 more die, 1,25...|  crime|  1.0|[19, more, die,, ...|[19, die,, 1,256,...|(2853,[3,34,242,1...|(2853,[3,34,242,1...|[-11.282700149276...|[5.60690821966456...|       1.0|\n",
      "|19 passengers die...|  crime|  1.0|[19, passengers, ...|[19, passengers, ...|(2853,[34,216,242...|(2853,[34,216,242...|[-14.091361953763...|[3.55489500490563...|       1.0|\n",
      "|19 women killed a...|  crime|  1.0|[19, women, kille...|[19, women, kille...|(2853,[7,88,242,1...|(2853,[7,88,242,1...|[-17.633725493880...|[3.10264921021428...|       1.0|\n",
      "|2 dead in Peshawa...|  other|  0.0|[2, dead, in, pes...|[2, dead, peshawa...|(2853,[32,126,260...|(2853,[32,126,260...|[-7.8119036039660...|[3.67069971798460...|       1.0|\n",
      "|21 killed, scores...|  crime|  1.0|[21, killed,, sco...|[21, killed,, sco...|(2853,[3,69,568,8...|(2853,[3,69,568,8...|[-1.1116842890233...|[6.67181321974157...|       1.0|\n",
      "|286 students get ...|  other|  0.0|[286, students, g...|[286, students, g...|(2853,[202,264],[...|(2853,[202,264],[...|[14.5499833379537...|[0.99999998420740...|       0.0|\n",
      "|3 killed in Pindi...|  crime|  1.0|[3, killed, in, p...|[3, killed, pindi...|(2853,[7,68,216],...|(2853,[7,68,216],...|[-2.8077498227152...|[6.30132532430632...|       1.0|\n",
      "|3 soldiers martyr...|  crime|  1.0|[3, soldiers, mar...|[3, soldiers, mar...|(2853,[68,109,606...|(2853,[68,109,606...|[-2.7109056033831...|[1.53150014086930...|       1.0|\n",
      "|3 terrorists kill...|  crime|  1.0|[3, terrorists, k...|[3, terrorists, k...|(2853,[7,46,54,68...|(2853,[7,46,54,68...|[-21.912423804524...|[6.08362686984271...|       1.0|\n",
      "|3 terrorists kill...|  crime|  1.0|[3, terrorists, k...|[3, terrorists, k...|(2853,[7,46,54,68...|(2853,[7,46,54,68...|[-21.912423804524...|[6.08362686984271...|       1.0|\n",
      "|4.7 magnitude ear...|  other|  0.0|[4.7, magnitude, ...|[4.7, magnitude, ...|(2853,[574,2642],...|(2853,[574,2642],...|[11.4369797039587...|[0.99999901678703...|       0.0|\n",
      "|5 ways to buy and...|  other|  0.0|[5, ways, to, buy...|[5, ways, buy, se...|(2853,[84,344],[1...|(2853,[84,344],[4...|[8.95265096093059...|[0.99997136492656...|       0.0|\n",
      "|5.3 magnitude ear...|  other|  0.0|[5.3, magnitude, ...|[5.3, magnitude, ...|(2853,[195,785],[...|(2853,[195,785],[...|[11.9979142200086...|[0.99999817724783...|       0.0|\n",
      "|70-year-of Pak-Ja...|  other|  0.0|[70-year-of, pak-...|[70-year-of, pak-...|        (2853,[],[])|        (2853,[],[])|[11.7346993572364...|[0.99999951730369...|       0.0|\n",
      "|74th death annive...|  other|  0.0|[74th, death, ann...|[74th, death, ann...|(2853,[30,132,698...|(2853,[30,132,698...|[16.3658910481248...|[0.99999999745640...|       0.0|\n",
      "|77 lose lives to ...|  crime|  1.0|[77, lose, lives,...|[77, lose, lives,...|(2853,[195,239,45...|(2853,[195,239,45...|[-8.4069274753148...|[9.10605131012593...|       2.0|\n",
      "+--------------------+-------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'subject',\n",
       " 'label',\n",
       " 'mytokens',\n",
       " 'filtered_tokens',\n",
       " 'rawFeatures',\n",
       " 'vectorizedFeatures',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Columns\n",
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-----+----------+\n",
      "|       rawPrediction|         probability|subject|label|prediction|\n",
      "+--------------------+--------------------+-------+-----+----------+\n",
      "|[13.7350531307451...|[0.99999995935182...|  other|  0.0|       0.0|\n",
      "|[-13.196458622153...|[3.95848358977358...|  crime|  1.0|       1.0|\n",
      "|[12.0155517729986...|[0.99999951612974...|  crime|  1.0|       0.0|\n",
      "|[14.0373767044725...|[0.99999996875660...|  other|  0.0|       0.0|\n",
      "|[-11.282700149276...|[5.60690821966456...|  crime|  1.0|       1.0|\n",
      "|[-14.091361953763...|[3.55489500490563...|  crime|  1.0|       1.0|\n",
      "|[-17.633725493880...|[3.10264921021428...|  crime|  1.0|       1.0|\n",
      "|[-7.8119036039660...|[3.67069971798460...|  other|  0.0|       1.0|\n",
      "|[-1.1116842890233...|[6.67181321974157...|  crime|  1.0|       1.0|\n",
      "|[14.5499833379537...|[0.99999998420740...|  other|  0.0|       0.0|\n",
      "+--------------------+--------------------+-------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rawPrediction','probability','subject','label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789808917197452"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+---+\n",
      "|title                                              |_2 |\n",
      "+---------------------------------------------------+---+\n",
      "|Three people died in Motorway collision near Attock|{} |\n",
      "+---------------------------------------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ex1 = spark.createDataFrame([\n",
    "    (\"Three people died in Motorway collision near Attock\",StringType())\n",
    "],\n",
    "# Column Name\n",
    "[\"title\"]\n",
    "\n",
    ")\n",
    "\n",
    "ex1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ex1 = lr_model.transform(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               title| _2|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|Three people died...| {}|[three, people, d...|[three, people, d...|(2853,[16,38,317,...|(2853,[16,38,317,...|[-3.9249638210230...|[2.29244688501167...|       1.0|\n",
      "+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ex1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|               title|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Three people died...|[-3.9249638210230...|[2.29244688501167...|       1.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ex1.select('title','rawPrediction','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'other': 0.0, 'crime': 1.0, 'health': 2.0, 'scary': 3.0}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1, featuresCol='vectorizedFeatures',labelCol='label')\n",
    "pipeline2 = Pipeline(stages=[tokenizer,stopwords_remover,vectorizer,idf,nb])\n",
    "modelNB = pipeline2.fit(trainDF)\n",
    "predictionsNB = modelNB.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248407643312102"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictionsNB)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+\n",
      "|               title|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "|Husband murdered ...|[-197.11185115063...|[2.12448689874153...|       1.0|\n",
      "+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ex12 = modelNB.transform(ex1)\n",
    "pred_ex12.select('title','rawPrediction','probability','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sparknlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf269ee04d05c42aad91061578575413d6682be793a5e82bde75bfd08faaead9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
